{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffic_generator import traffic_generator\n",
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPOLOGY = [\"Node_i\", \"Node_j\", \"Node_k\", \"Node_l\", \"Node_m\"]\n",
    "DATA_DICT = {\n",
    "    \"Node_i\":[10, 20, 30, 40, 1],\n",
    "    \"Node_j\":[15, 40, 25, 35, 1],\n",
    "    \"Node_k\":[12, 18, 40, 25, 1],\n",
    "    \"Node_l\":[40, 12, 15, 23, 1],\n",
    "    \"Node_m\":[20, 13, 25, 11, 12]\n",
    "}\n",
    "link_bandwidth = 2 # 应该以邻接矩阵给出\n",
    "traffic_distribution = \"uniform\"\n",
    "link_delay = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Node_i': [97, 103, 135, 134, 16], 'Node_j': [97, 103, 135, 134, 16], 'Node_k': [97, 103, 135, 134, 16], 'Node_l': [97, 103, 135, 134, 16], 'Node_m': [97, 103, 135, 134, 16]}\n"
     ]
    }
   ],
   "source": [
    "# Ring-AllReduce_algorithms\n",
    "\n",
    "NODES_NUM = len(TOPOLOGY)\n",
    "MAX_STEPS = 2 * (NODES_NUM - 1)\n",
    "FINAL_DICT = DATA_DICT\n",
    "for step in range(MAX_STEPS):\n",
    "    REDUCE_FLAG = True\n",
    "    if step >= (NODES_NUM - 1):\n",
    "        REDUCE_FLAG = False\n",
    "    # REDUCE_FLAG用于判断Ring-AllReduce处于Reduce阶段还是Broadcast阶段\n",
    "    # Reduce阶段数据需要进行处理 (梯度聚合), Broadcast阶段数据只需要进行传输\n",
    "    # 但是对于仿真而言传输数据量是固定的, 好像不需要考虑这个. \n",
    "    for node_id in range(NODES_NUM):\n",
    "        data_index = ((node_id + step*(NODES_NUM-1)) % NODES_NUM)\n",
    "        # print(data_index)\n",
    "        if node_id == NODES_NUM-1:\n",
    "            src_node = TOPOLOGY[node_id]\n",
    "            dst_node = TOPOLOGY[0]\n",
    "            if REDUCE_FLAG:\n",
    "                FINAL_DICT[dst_node][data_index] += FINAL_DICT[src_node][data_index]\n",
    "                continue\n",
    "            FINAL_DICT[dst_node][data_index] = FINAL_DICT[src_node][data_index]\n",
    "            continue\n",
    "        src_node = TOPOLOGY[node_id]\n",
    "        dst_node = TOPOLOGY[node_id+1]\n",
    "        if REDUCE_FLAG:\n",
    "            FINAL_DICT[dst_node][data_index] += FINAL_DICT[src_node][data_index]\n",
    "            continue\n",
    "        FINAL_DICT[dst_node][data_index] = FINAL_DICT[src_node][data_index]\n",
    "\n",
    "print(FINAL_DICT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240.0\n"
     ]
    }
   ],
   "source": [
    "# Broadcast_algorithms (Based on Binary-Tree)\n",
    "\n",
    "father_nodes_list = [\"Node_i\"]\n",
    "son_nodes_list = [\"Node_j\", \"Node_k\", \"Node_l\", \"Node_m\", \"Node_n\", \"Node_o\"]\n",
    "data_size = 10000\n",
    "\n",
    "link_bandwidth = 100\n",
    "link_delay = 20\n",
    "# 这里的link_delay和link_bd都应该从邻接矩阵里面取而不是直接给出\n",
    "SUM_TIME = 0\n",
    "NODES_CNT = 1 # 记录所有收到数据的节点个数, 这里也可以用log2来做因为是基于二叉树的, 但是本质没差. 加一个计数器好像更简单一些\n",
    "while NODES_CNT < len(father_nodes_list) + len(son_nodes_list):\n",
    "    temp_father_nodes_list = []\n",
    "    max_time = 0\n",
    "    # max_time用来记录每层Tree传输的时候的最大时间, 用这个最大时间作为该层的传输时间, 最终将多层的传输时间求和得到Broadcast的完成时间\n",
    "    for father_node in father_nodes_list:\n",
    "        for index, son_node in enumerate(son_nodes_list):\n",
    "            time = data_size / link_bandwidth + link_delay\n",
    "            # 正确的方法是这里应该根据不同的link_bd和link_delay计算出不同的两个node之间的时间\n",
    "            if time > max_time:\n",
    "                max_time = time\n",
    "            NODES_CNT += 1\n",
    "            _ = son_nodes_list.pop(index)\n",
    "            temp_father_nodes_list.append(son_node)\n",
    "            break\n",
    "    SUM_TIME += max_time\n",
    "    father_nodes_list += temp_father_nodes_list\n",
    "print(SUM_TIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "node_id:h2, cnt:0\n",
      "\n",
      "node_id:h1, cnt:0\n",
      "2\n",
      "node_id:h3, cnt:0\n",
      "3\n",
      "node_id:h4, cnt:0\n",
      "4\n",
      "node_id:h5, cnt:0\n",
      "node_id:h1, cnt:1\n",
      "node_id:h2, cnt:1\n",
      "node_id:h3, cnt:1\n",
      "node_id:h4, cnt:1\n",
      "node_id:h5, cnt:1\n",
      "node_id:h1, cnt:2\n",
      "node_id:h2, cnt:2\n",
      "node_id:h3, cnt:2\n",
      "node_id:h4, cnt:2\n",
      "node_id:h5, cnt:2\n",
      "node_id:h1, cnt:3\n",
      "node_id:h2, cnt:3\n",
      "node_id:h3, cnt:3\n",
      "node_id:h4, cnt:3\n",
      "node_id:h5, cnt:3\n",
      "node_id:h1, cnt:4\n",
      "node_id:h2, cnt:4\n",
      "node_id:h3, cnt:4\n",
      "node_id:h4, cnt:4\n",
      "node_id:h5, cnt:4\n",
      "node_id:h1, cnt:5\n",
      "node_id:h2, cnt:5\n",
      "node_id:h3, cnt:5\n",
      "node_id:h4, cnt:5\n",
      "node_id:h5, cnt:5\n",
      "node_id:h1, cnt:6\n",
      "node_id:h2, cnt:6\n",
      "node_id:h3, cnt:6\n",
      "node_id:h4, cnt:6\n",
      "node_id:h5, cnt:6\n",
      "node_id:h1, cnt:7\n",
      "node_id:h2, cnt:7\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m     exec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthread\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.start()\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(nodes_list)):\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthread\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.join()\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\yhbia\\.conda\\envs\\py310\\lib\\threading.py:1096\u001b[0m, in \u001b[0;36mThread.join\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1096\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\yhbia\\.conda\\envs\\py310\\lib\\threading.py:1116\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1117\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id:h3, cnt:7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_id:h4, cnt:7\n",
      "node_id:h5, cnt:7\n"
     ]
    }
   ],
   "source": [
    "from threading import Thread\n",
    "import time\n",
    "\n",
    "nodes_list = [\"h1\", \"h2\", \"h3\", \"h4\", \"h5\"]\n",
    "node_status_matrix = {\n",
    "    \"h1\": 1,\n",
    "    \"h2\": 1,\n",
    "    \"h3\": 1,\n",
    "    \"h4\": 1,\n",
    "    \"h5\": 1\n",
    "}\n",
    "# 0: waiting for data\n",
    "# 1: ready to send\n",
    "# 2: finished\n",
    "def reduce_send(node_id, node_num, data_size):\n",
    "    cnt = 0\n",
    "    global nodes_list\n",
    "    node_index = nodes_list.index(node_id)\n",
    "    print(node_index)\n",
    "    if node_index == len(nodes_list)-1:\n",
    "        src_node = node_id\n",
    "        dst_node = nodes_list[0]\n",
    "    else:\n",
    "        src_node = node_id\n",
    "        dst_node = nodes_list[node_index+1]\n",
    "    while True:\n",
    "        if cnt == 2 * (node_num - 1):\n",
    "            break\n",
    "        global node_status_matrix\n",
    "        if node_status_matrix[src_node] == 1:\n",
    "            send_time = data_size / 2\n",
    "            print(f\"node_id:{node_id}, cnt:{cnt}\")\n",
    "            # ---\n",
    "            # send\n",
    "            time.sleep(node_index)\n",
    "            node_status_matrix[src_node] = 0\n",
    "            node_status_matrix[dst_node] = 1\n",
    "            cnt += 1\n",
    "\n",
    "# thread1 = Thread(target=reduce_send, args=(\"h1\",5,10))\n",
    "# thread2 = Thread(target=reduce_send, args=(\"h2\",5,10))\n",
    "# thread3 = Thread(target=reduce_send, args=(\"h3\",5,10))\n",
    "# thread4 = Thread(target=reduce_send, args=(\"h4\",5,10))\n",
    "# thread5 = Thread(target=reduce_send, args=(\"h5\",5,10))\n",
    "\n",
    "\n",
    "# thread1.start()\n",
    "# thread2.start()\n",
    "# thread3.start()\n",
    "# thread4.start()\n",
    "# thread5.start()\n",
    "\n",
    "# thread1.join()\n",
    "# thread2.join()\n",
    "# thread3.join()\n",
    "# thread4.join()\n",
    "# thread5.join()\n",
    "\n",
    "\n",
    "for i in range(len(nodes_list)):\n",
    "    exec(\"thread{} = Thread(target=reduce_send, args=('h{}',5, 10))\".format(i+1, i+1))\n",
    "\n",
    "for i in range(len(nodes_list)):\n",
    "    exec(\"thread{}.start()\".format(i+1))\n",
    "\n",
    "for i in range(len(nodes_list)):\n",
    "    exec(\"thread{}.join()\".format(i+1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
